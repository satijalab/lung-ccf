{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeletonization of volumes\n",
    "\n",
    "## Pipeline\n",
    "- Open `NRRD` volume files with Fiji.\n",
    "- Visualize volume using Fiji 3D viewer.\n",
    "- Run `Skeletonize` plugin.\n",
    "- Run `Analyze Skeleton` plugin (tick boxes for full output).\n",
    "- Export skeleton info as `CSV` files.\n",
    "- Run code in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some additional doc\n",
    "\n",
    "### Convert `.mha` to `.nrrd`\n",
    "- Open `.mha` file with Fiji.\n",
    "- Convert to 8-bit format.\n",
    "    - Image -> Type -> 8-bit\n",
    "- Normalize histogram (_ie_ mesh values set to 255).\n",
    "    - Process -> Enhance contrast -> tick normalize, process all slices, use stack histogram\n",
    "- Export as `.nrrd`.\n",
    "- Exported `NRRD` files available in Box folder `tommaso_data`.\n",
    "\n",
    "### About skeletonization algorithm\n",
    "- from Lee et al. 1994 900+ citations [paper](http://155.98.16.52/devbuilds/biomesh3d/FEMesher/references/lee94-3dskeleton.pdf).\n",
    "- Implemented in ITK (Homann 2007) [link](http://www.sci.utah.edu/~dmw/FEMesher/references/ITKbinaryThinningImageFilter3D.pdf)\n",
    "- Implemented in Fiji. Plugin `Skeletonize3D` (last update 2017) [link](https://imagej.net/Skeletonize3D).\n",
    "- Implemented in (Python module) `skelet3d` [link](https://pypi.org/project/skelet3d/1.5.13/).\n",
    "- Implemented in MATLAB implementation [link](https://github.com/phi-max/skeleton3d-matlab).\n",
    "- Implemented in `scikit-image` as `skeletonize_3d` from scikit-image [doc](https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyvolume as ipv\n",
    "import ipyvolume.pylab as p3\n",
    "import nrrd\n",
    "import re\n",
    "import tlib.lung as tlu  # tommaso library - lung project\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Load data and visualize segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `slicer_test` segmentation and analysis. Replace paths w your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load segmentation\n",
    "slicer_data_path = os.path.join(home, 'datasets/lung/slicer/on_sample_ct_data/airways_seg_int8.nrrd')\n",
    "assert os.path.isfile(slicer_data_path)\n",
    "slicer_data, slicer_data_info = nrrd.read(slicer_data_path)\n",
    "\n",
    "# Load skeleton analysis\n",
    "slicer_skeleton_path = os.path.join(home, 'datasets/lung/slicer/on_sample_ct_data/skeleton_analysis.csv')\n",
    "assert os.path.isfile(slicer_skeleton_path)\n",
    "slicer_skeleton = tlu.Skeleton(slicer_skeleton_path)\n",
    "# slicer_df = pd.read_csv(skeleton_path)\n",
    "\n",
    "# Visualize segmentation\n",
    "# ipv.quickvolshow(slicer_data, opacity=[.2, 0, 0], level=[.21, 1, .9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for `D175` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load segmentation\n",
    "d175_data_path = os.path.join(home, 'datasets/lung/segmentation/D175_segmented.nrrd')\n",
    "assert os.path.isfile(d175_data_path)\n",
    "d175_data, d175_data_info = nrrd.read(d175_data_path)\n",
    "\n",
    "# Load skeleton analysis\n",
    "d175_skeleton_path = os.path.join(home, 'datasets/lung/segmentation/D175_skeleton.csv')\n",
    "assert os.path.isfile(d175_skeleton_path)\n",
    "d175_skeleton = tlu.Skeleton(d175_skeleton_path)\n",
    "# d175_df = pd.read_csv(d175_skeleton_path)\n",
    "\n",
    "# Visualize segmentation\n",
    "# ipv.quickvolshow(slicer_data, opacity=[.2, 0, 0], level=[.21, 1, .9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data to fine tune `opacity`, `level` and `xyzlim` for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicer_info = {\n",
    "    'opacity': [.7, 0, 0],\n",
    "    'level': [.2, 1, .9],\n",
    "    'level_width': .08,\n",
    "    'max_opacity': .7,\n",
    "    'xyz_lim': 500,\n",
    "}\n",
    "# ipv.figure()\n",
    "# ipv.volshow(slicer_data, opacity=slicer_info['opacity'],  level=slicer_info['level'],\n",
    "#             level_width=slicer_info['level_width'],  \n",
    "#             max_opacity=slicer_info['max_opacity'])\n",
    "# ipv.xyzlim(0, slicer_info['xyz_lim'])\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d175_info = {\n",
    "    'opacity': [.7, 0, 0],\n",
    "    'level': [.2, 1, .9],\n",
    "    'level_width': .08,\n",
    "    'max_opacity': .7,\n",
    "    'xyz_lim': 1000,\n",
    "}\n",
    "# ipv.figure()\n",
    "# ipv.volshow(d175_data, opacity=d175_info['opacity'],  level=d175_info['level'],\n",
    "#             level_width=d175_info['level_width'],  \n",
    "#             max_opacity=d175_info['max_opacity'])\n",
    "# ipv.xyzlim(0, d175_info['xyz_lim'])\n",
    "# ipv.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_figure(data, info, skeleton):\n",
    "    \"\"\"Helper that overlays ending/branching points to segmentation\"\"\"\n",
    "    sphere_size = .8\n",
    "    ipv.figure()\n",
    "    ipv.volshow(data, opacity=info['opacity'], \n",
    "                level=info['level'],\n",
    "                level_width=info['level_width'],  \n",
    "                max_opacity=info['max_opacity'])\n",
    "\n",
    "    xs_1, ys_1, zs_1 = skeleton.get_points_w_connectivity(1)\n",
    "    ipv.scatter(zs_1, ys_1, xs_1, marker='sphere', color='blue', size=sphere_size)\n",
    "\n",
    "    xs_3, ys_3, zs_3 = skeleton.get_points_w_connectivity(3)\n",
    "    ipv.scatter(zs_3, ys_3, xs_3, marker='sphere', color='yellow', size=sphere_size)\n",
    "\n",
    "    ipv.xyzlim(0, info['xyz_lim'])\n",
    "    ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figure(data=slicer_data, info = slicer_info, skeleton = slicer_skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show_figure(data=d175_data, info = d175_info, skeleton = d175_skeleton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Where do we go from here\n",
    "\n",
    "- Andrea Tagliasacchi: expert in skeletonization. Method [paper](https://ialhashim.github.io/files/documents/tag_sgp12.pdf), perhaps works better than ours? Implemented in [obscure framework](https://github.com/ataiya/starlab-mcfskel) and [CGAL](https://doc.cgal.org/latest/Surface_mesh_skeletonization/index.html) by student.\n",
    "- [SkeletonLab](http://francescousai.info/skel_lab.html), software for easy editing of skeletons. Learn how to export our skeleton in right format then edit it using their framework?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
